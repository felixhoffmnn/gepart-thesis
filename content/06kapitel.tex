%!TEX root = ../dokumentation.tex

\chapter{Fazit} \label{ch:conclusion}

Abschließend werden zunächst die Erkenntnisse und Abläufe dieser Arbeit zusammengefasst. In der anschließenden Reflexion werden zum einen die Forschungsfragen beantwortet und die Ergebnisse bewertet. Schlussendlich werden im Ausblick offene Untersuchungen dokumentiert, die sich in dieser Arbeit ergeben haben oder außerhalb des Umfanges dieser Arbeit lagen.

\section{Zusammenfassung}

Wie in \autoref{subsec:heterogenitätParteien} dargelegt, koalieren die Union und \ac{SPD} in der \num{19}. Wahlperiode. Die Opposition besteht demnach aus den Grünen, \ac{FDP}, Linken und der \ac{AfD}. In dem Untersuchungszeitraum dominieren Themen wie Migration, Klimaschutz und Pandemie den politischen Diskurs. In \autoref{ch:crispDm_1} werden zunächst die Tweets, Reden und Wahlprogramme analysiert und bereinigt. Durch die Bereinigung hat sich die Anzahl an Tweet drastisch verringert. Die Wahlprogramm-Paragraphen sind gleich geblieben, während die Reden durch die Aufteilung mehr sind als zuvor. In der Analyse zeigen sich textsortenspezifische Muster bei der Länge und dem Sentiment der Dokumente. Mittels simpler Wortwolken lassen sich schon erste Merkmale zur Klassifikation der einzelnen Parteien ableiten. Anhand des Sentiments kann auf allen Textsorten eine Trennung der Parteien nach Regierung und Opposition vorgenommen werden.

In \autoref{ch:crispDm_2} zeigt sich, dass die Modelle Schwierigkeiten dabei haben, Parteien, die sich politisch nahe stehen, eindeutig zu klassifizieren. Bei dem Trainieren der Modelle treten vermehrt Limitationen bezüglich der verfügbaren Ressourcen auf. Insgesamt schneiden die Transformer-Modelle am besten ab, wobei sich lediglich das DistilBERT Modell auf dem gesamten Datensatz trainieren lässt. Auf dem unbalancierten und balancierten Datensatz erreicht das Modell \(F_1\) Scores zwischen \numrange{0.58}{0.60}. Besonders die \ac{AfD} lässt sich am akkuratesten klassifizieren, wohingegen andere, politisch nahestehende Parteien zu Verwechselungen neigen.

Anschließend werden weitere Untersuchungen zu Thesen vorgenommen, die zuvor definiert wurden, oder sich im Laufe der Arbeit ergeben haben. Alle drei Untersuchungen fallen positiv aus.

\section{Reflexion}

Wie in dieser Arbeit dargelegt, ist es möglich, mit diversen \ac{ML}-Ansätzen und mehreren Textsorten ein solides Klassifikationsmodell trainieren. Die verschiedenen Modelle erreichen auf dem kombinierten, balancierten Datensatz \(F_1\) Scores von bis zu \num{0.58}. Die unterschiedlichen Modelle in \autoref{ch:crispDm_2}  unterscheiden sich sehr stark in der Trainingsgeschwindigkeit. Wie sich aus der Analogie zwischen dem Namen dieser Arbeit -- GePart -- und dem Tier Gepard ergibt, war das initiale Ziel dieser Arbeit ein Modell zu wählen, dass eine kurze Trainingszeit gewährleistet wird und mit dem sich schnell Inferenzen berechnen lassen. \ft erfüllt beide dieser Kriterien. Schlussendlich erschien es jedoch wichtiger ein Modell zu wählen, dass komplexere Satzstrukturen besser erfassen kann. DistilBERT stellt somit einen Kompromiss dar. Es trainiert bei Weitem langsamer als \ft und doch schneller als größere Sprachmodelle.

Dennoch erweisen sich die Daten in Kombination mit den verwendeten Modellen als Herausforderung. Aus \autoref{subsec:furtherExperiments} geht hervor, dass dem Modell unbekannte Textsorten signifikant schlechter klassifizierbar sind. Daraus folgt, dass das bereitgestellte Modell in der aktuellen Version nicht für unbekannte Arten von Text geeignet ist.

% Für weitere Untersuchungen wäre es daher relevant mehr Textsorten zu sammeln, um eine breitere Abdeckung in klassifizierbaren Texten zu erhalten.

Zusätzlich dazu zeigt sich, dass umso länger der Untersuchungszeitraum ist, die Modellperformance in Form des \(F_1\) Scores abnimmt. Durch die Einschränkung auf die \num{19}. Wahlperiode sind die resultierenden Modelle nur auf die Themen in diesem Zeitraum ausgerichtet und erreichen insgesamt bessere Werte. Ein Bias durch die Regierung im Untersuchungszeitraum kann nicht ausgeschlossen werden, sodass Vorhersagen für Texte mit anderen Regierungskonstellationen schlechter funktionieren können. 

Zusammenfassend ist festzustellen, dass die Modelle sehr anfällig für zeitliche Abweichungen, alternative Textsorten, politische Themen und die Länge von Texten ist. Ferner ist anzunehmen, dass abweichende Regierungskonstellationen ebenfalls einen signifikanten Effekt auf den politischen Diskurs und somit die Modellperformance haben.

% Wie bei \textcite{biessmann_predicting_2016} lassen sich besonders kurze Texte auf Satz-Ebene signifikant schlechter klassifizieren als längere Texte auf Dokumenten-Ebene.

\section{Ausblick}

Ausgehend von den in dieser Arbeiten durchgeführten Analysen und Untersuchungen ergeben sich weitere Ansatzpunkte, von denen ausgehend verwandte Forschungsfragen untersucht werden können.

Wie sich in \autoref{subsec:outOfDomain} zeigt, hat die Größe des Trainings-Datensatzes einen Einfluss auf die resultierende Modellperformance. Um die Datenmenge zu erhöhen, könnten in weiteren Untersuchung ebenfalls Retweets für das Training genutzt werden. Duplikate sollten dennoch herausgefiltert werden. Auch bei den anderen Datensätzen könnte die Filterung gelockert werden, um weniger Einträge verwerfen zu müssen. Bei den Wahlprogrammen sowie bei den Reden käme eine Erhöhung der Mindestlänge der Texte infrage. Es besteht dabei das Risiko, dass irrelevante Texte hinzukommen und einen Störfaktor beim Training darstellen. Andererseits können die zusätzlichen Einträge auch hilfreich sein, um die Modellperformance zu verbessern. Weitere Möglichkeiten, um die Informationsdichte der vorhandenen, bereinigten Daten zu erhöhen, wäre es, Emojis in Klartext umzuwandeln. Emojis sind, besonders auf Plattformen wie Twitter, ein sprachliches Mittel und enthalten weitere Informationen über den Kontext und Sentiment eines Textes \autocite{guhr_training_2020}.

Wie bereits zuvor beschrieben, bietet es sich an, weitere Textsorten in die Auswahl an Datensätzen für Training aufzunehmen. Die Untersuchung zu der Performance des \ft Modells auf out-of-domain Daten hat gezeigt, dass Klassifikationen ohne bedeutenden Verlust an Genauigkeit nur auf Textsorten möglich ist, auf denen auch trainiert wurde. Weitere Arten von Text würden die generalisierte Nutzbarkeit des auf dem kombinierten Datensatz trainierten Modells steigern.

Wie schon in \autoref{subsec:discussion} angedeutet, könnte eine neutrale Klasse hinzugefügt werden. Zusätzlich sollte sichergestellt werden, dass die Trainingsdaten nicht nur von einem Politiker verfasst wurden, sondern einen eindeutigen politischen Kontext aufweisen. Hierfür könnten Modelle verwendet werden, die feststellen, ob ein Text Fakten enthält oder nicht. Für englische Texte gibt es solche Modelle bereits. Ein alternativer Ansatz zum Hinzufügen einer neutralen Klasse wäre es auch Datensätze zu inkludieren, die noch keinem Politiker oder Partei zugeordnet sind. Diese müssen voraussichtlich aber manuell gekennzeichnet werden.

Wie sich gezeigt hat, führ die Klassifikation von mehreren Klassen zu einer zusätzlichen Komplexität. Alternativ dazu können die Modelle nicht auf die Parteien, sondern Parteigruppen -- beispielsweise links und rechts -- trainiert werden. Ferner sind auch von Parteien unabhängige Klassifikationen denkbar, wie zwischen politischen und unpolitisch Texten oder solchen, die einen Fakt enthalten oder nicht. Diese wären ebenfalls dazu geeignet, um Einschätzungen über neue, noch nicht betrachtete Texte oder Medien zu bekommen. Als Alternative zur Reduzierung der Klassen ließen sich ebenfalls weitere Metainformationen für das Training der Modelle verwenden. Mithilfe des Multimodal Transformers Projekts\footnote{\href{https://github.com/jianzhnie/MultimodalTransformers}{https://github.com/jianzhnie/MultimodalTransformers}} könnten zusammen mit dem reinen Text weitere numerische oder kategoriale Features, wie das Sentiment, die Faktendichte oder die Tatsache, ob im Text gegendert wird, helfen, die Modellperformance zu verbessern.

An mehreren Stellen dieser Arbeit werden einschränkende Maßnahmen getroffen, weil die zur Verfügung stehenden Ressourcen für die gewollten Konfigurationen beim Training nicht ausreichen. Bevor jedoch die Modelle auf mehr Daten trainiert werden können, ist es relevant, die Ressourcen für das Training entweder vertikal oder horizontal zu skalieren. Zusätzlich könnten mit mehr Ressourcen ebenfalls neuere State-of-the-Art Verfahren genutzt werden.
